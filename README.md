# Paggo - OCR Case

![Status](https://img.shields.io/badge/status-conclu√≠do-green)

> Desafio t√©cnico fullstack para o Paggo Group, construindo uma aplica√ß√£o de OCR e intera√ß√£o com LLM usando Next.js, NestJS e Prisma.

## üöÄ Link para a Aplica√ß√£o

**Voc√™ pode acessar a aplica√ß√£o deployada aqui: [https://futurolink.com](https://link-futuro)**

---

## üìã √çndice

* [Sobre o Projeto](#-sobre-o-projeto)
* [‚ú® Demonstra√ß√£o](#-demonstra√ß√£o)  
* [Tecnologias Utilizadas](#-tecnologias-utilizadas)
* [Como Rodar o Projeto Localmente](#-como-rodar-o-projeto-localmente)
* [Decis√µes de Arquitetura](#-decis√µes-de-arquitetura)

---

## ‚ú® Demonstra√ß√£o

A aplica√ß√£o possui um fluxo completo, desde uma landing page de apresenta√ß√£o at√© um dashboard funcional e interativo.

### Dashboard Principal
*A tela principal da aplica√ß√£o, onde o usu√°rio faz o upload de documentos, visualiza o hist√≥rico e interage com os resultados.*
![Dashboard da Aplica√ß√£o](.github/assets/dashboard.png)

<details>
<summary>Clique para ver mais telas (Homepage e Autentica√ß√£o)</summary>

### Homepage
*Landing page com a apresenta√ß√£o do projeto, tecnologias e arquitetura.*
![Homepage](.github/assets/MainPage.png)

### Telas de Autentica√ß√£o
*Fluxo de registro e login com feedback visual para o usu√°rio.*
![Tela de Registro](.github/assets/register.png)
![Tela de Login](.github/assets/login.png)

</details>

---

## üìñ Sobre o Projeto

Este projeto implementa uma solu√ß√£o que permite aos usu√°rios autenticados fazerem upload de documentos (como faturas), extrair o texto via OCR e interagir com um modelo de linguagem (LLM) para obter explica√ß√µes e informa√ß√µes sobre os dados extra√≠dos.

---

## ‚ú® Tecnologias Utilizadas

Este projeto foi desenvolvido com as seguintes tecnologias:

* **Frontend:** Next.js, React, Tailwind CSS
* **Backend:** NestJS, TypeScript
* **Banco de Dados:** PostgreSQL (via Prisma ORM)
* **Autentica√ß√£o:** NextAuth.js (com JWT)
* **OCR:** Tesseract.js
* **LLM:** Google Gemini API
* **Deployment:** Vercel

---

## ‚öôÔ∏è Como Rodar o Projeto Localmente

Siga os passos abaixo para configurar e rodar o projeto em seu ambiente local.

**Pr√©-requisitos:**
* [Node.js](https://nodejs.org/) (vers√£o LTS)
* [pnpm](https://pnpm.io/installation)
* [Docker](https://www.docker.com/) (para o banco de dados)

**Passo a passo:**

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/Manelima/paggo-ocr-case.git](https://github.com/Manelima/paggo-ocr-case.git)
    cd paggo-ocr-case
    ```

2.  **Configure as Vari√°veis de Ambiente:**
    * Na raiz do projeto, crie um arquivo `.env` a partir do exemplo:
        ```bash
        cp .env.example .env
        ```
    * Abra o arquivo .env e preencha todas as vari√°veis necess√°rias (URL do banco, segredos de JWT, chave da API do Google Gemini, etc.).

3.  **Instale as depend√™ncias:**
    ```bash
    pnpm install
    ```

4.  **Suba o banco de dados (se usar Docker):**
    ```bash
    docker-compose up -d
    ```

5.  **Aplique as migra√ß√µes do banco de dados:**
    ```bash
    pnpm --filter api prisma migrate dev
    ```
    *O filtro `--filter api` garante que o comando rode apenas no projeto do backend.*

6.  **Inicie a aplica√ß√£o:**
    ```bash
    pnpm dev
    ```
    *Este comando ir√° iniciar tanto o frontend quanto o backend em modo de desenvolvimento.*

7.  Acesse `http://localhost:3000` em seu navegador.

---

## üß† Decis√µes de Arquitetura (Opcional, mas impressiona!)

* **Monorepo com PNPM Workspaces:** Escolhi esta abordagem para facilitar o compartilhamento de tipos (especialmente os tipos gerados pelo Prisma) entre o frontend e o backend, garantindo consist√™ncia e evitando duplica√ß√£o de c√≥digo.
* **Processamento Ass√≠ncrono de OCR:** A extra√ß√£o de texto √© uma tarefa demorada. Para n√£o bloquear a requisi√ß√£o do usu√°rio, o processo √© executado em background (ex: usando filas com BullMQ ou uma simples `Promise`), melhorando a experi√™ncia do usu√°rio.
* **Autentica√ß√£o com NextAuth.js:** Optei por gerenciar a sess√£o no lado do cliente com NextAuth.js pela sua simplicidade de integra√ß√£o com o ecossistema Next.js, enquanto o backend NestJS apenas valida os tokens JWT, mantendo os servi√ßos desacoplados.
* **Escolha do LLM (Google Gemini):** Para a integra√ß√£o com o LLM, optei pela API do Google Gemini devido √† sua alta qualidade e ao seu generoso n√≠vel de acesso gratuito, que se alinha perfeitamente aos requisitos de um prot√≥tipo funcional sem incorrer em custos de desenvolvimento.

---